# -*- coding: utf-8 -*-
"""Fase1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14zp4hG0IT6XYkHH0FRjrO--GT6co1h--

# Revisão dos artigos publicados
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
# %unload_ext google.colab.data_table

path = "/content/drive/MyDrive/ufrn/mestrado/DIM0868 -  TOPICOS AVANCADOS EM SISTEMAS INTEGRADOS E DISTRIBUIDOS II/Revisão dos artigos publicados/scopus.csv"
df = pd.read_csv(path)

"""## Papers publicados na International Conference on Dependable Systems and Networks Workshops"""

df.info()

"""## **1ª Fase**

### Aplicando filtro de campos e limpando entradas indesejadas
"""

reg_string = "tolerance|iot|things|dependable|dependability|cyber|sensor|machine to machine|m2m"
search_box = ['Title', 'Index Keywords', 'Author Keywords', 'Abstract']
df['search_box'] = ''

for search in search_box:
  df['search_box'] =  df['search_box'].map(str) + ' ' + df[search].map(str)
df = df[df['Authors'] != '[No author name available]']
# df_aux = df[(df['Authors'] != '[No author name available]') & (df['search_box'].str.contains(reg_string))]
# df_aux.info()
df.info()

"""# Sobre a conferencia
##Qualitativos

### Tipo de trabalhos
"""

import matplotlib.pyplot as plt
print("TIPOS DE DOCUMENTOS PUBLICADOS")
display(df['Document Type'].value_counts())

pie_chart = df['Document Type'].value_counts().plot(figsize=(7, 7), kind='pie', title='Document Type', legend='left', y="Document Type", autopct="%.0f", ylabel='')

"""#### Distribuição das Citações, Papers e Autores/Ano"""

print("DISTRIBUIÇÃO DAS CITAÇÕES POR ANO")
distribuicao = df.groupby('Year').agg([('Papers','count'), ('Citacoes','sum')])[[('Cited by', 'Citacoes'), ('Authors', 'Papers')]].reset_index()
distribuicao
distribuicao.columns = ['Year', 'Num Citacoes', 'Num Papers']

autores = df
autores['ids'] = df["Author(s) ID"].str.split(";")
autores['nomes'] = df["Authors"].str.split(",")
keys = autores.explode('ids')['ids']
values = autores.explode('nomes')['nomes']
keys = list(filter(None, keys))
df['num_autores'] = df["Author(s) ID"].str.split(';').map(len)-1
print('Autores distintos:', len(set(keys)) )
test = df.groupby('Year').agg({'num_autores':'sum'}).reset_index()
test = pd.merge(test, distribuicao, on='Year', sort=False)

test.plot(subplots=True, sharex=True, x='Year', figsize=(10, 10), grid=True)
plt.show()
test['ratio'] = test['Num Citacoes'] / test['Num Papers']
test['ratio2'] = test['num_autores'] / test['Num Papers']
test.mean()

"""### Tendencias

#### Por palavras-Chave
"""

from collections import Counter

df['Index Keywords'] = df['Index Keywords'].astype(str)
df['Author Keywords'] = df['Author Keywords'].astype(str)
df['terms'] =  df['Author Keywords'].map(str) + "; " + df['Index Keywords'].map(str)

def get_keywords_counted(df):
  keywords = list()
  [keywords.extend(value.split('; ')) for value in df['terms'].unique().tolist() if type(value) != float]
  keywords_dict = dict(Counter(keywords))

  sorted_dict = dict(sorted(keywords_dict.items(),
                            key=lambda item: item[1],
                            reverse=True))

  termos = list(sorted_dict.items())
  termos = pd.DataFrame(termos, index = np.arange(len(termos)), columns=['Keyword', df.Year.iloc[0]])
  # termos['Keyword'] = termos['Keyword'].str.lower()
  return termos
  
df['terms'] = df['terms'].str.lower()
grouped = df.groupby("Year")
for k, year in enumerate(grouped.groups.keys()):
  result = get_keywords_counted(grouped.get_group(year))  
  if k == 0:
    dt = result
  else:
    dt = pd.merge(dt, result, on=["Keyword"], how='outer')



dt = dt.fillna(0)
dt['Total'] = dt.sum(axis=1)
dt.drop(dt.index[:1], inplace=True)

display(dt.sort_values('Total', ascending=False))

print("VARIAÇÃO DO TERMO 'FAULT'.")

dt['Num Ocorrencias'] = dt['Total']
display(dt[dt['Keyword'].str.contains('fault')][['Keyword','Num Ocorrencias']].sort_values('Num Ocorrencias', ascending=False))


print("Termos Mais recorrentes em 2020.")
display(dt.sort_values(2020, ascending=False))

import re

top_keywords = '|'.join(dt.sort_values('Total', ascending=False)['Keyword'][0:10])

print(top_keywords)

sample = df.sort_values('Cited by', ascending=False)
filter_by_keywords = sample['Index Keywords'].str.contains(top_keywords)
filter_by_year = sample['Year'] >= 2000 
columns = ['Authors', 'Title', 'Year', 'Cited by', 'Index Keywords']
sample = sample[columns].fillna(0)

display(sample[filter_by_year])
sample['Cited by'].mean()

from statsmodels.tsa.seasonal import seasonal_decompose

dt.sort_values('Total', ascending=False)[:20]

